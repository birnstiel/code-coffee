{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Coffee: 17.05.22\n",
    "\n",
    "# Yet another python accelerator: An introduction to ***numba***\n",
    "\n",
    "We will take a look at the numba module which tries to achieve C-style performance for Python/Numpy based algorithms by compiling python into equivalent machine code on runtime. We will cover basic usage and limitations while appreciating significant speedup with minimal changes to existing code.  \n",
    "\n",
    "The very good, but sometimes short ***numba*** documentation is available here\n",
    "> https://numba.pydata.org/numba-doc/dev/index.html\n",
    "\n",
    "There is also a nice video by \"Jack of Some\" on YouTube which is very easy to follow and explains basic usage and some pitfalls with ***numba***\n",
    "> https://www.youtube.com/watch?v=x58W9A2lnQc\n",
    "\n",
    "This introduction is inspired by both ;)  \n",
    "\n",
    "## Installation\n",
    "\n",
    "Its as easy as it can be and is even available in Anaconda/Miniconda\n",
    "> pip install numba \n",
    "\n",
    "> conda install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic modules we are going to use\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import jit, njit, vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 s ± 34.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.83 s ± 39.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.78 s ± 19.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.73 s ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = sum_np(inp)\n",
    "\n",
    "%timeit _ = sum_nb(inp)\n",
    "\n",
    "%timeit _ = sum_nb2(inp)\n",
    "\n",
    "%timeit _ = sum_nb3(lol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *@jit* decorator\n",
    "\n",
    "Arguably the most important function decorator from the numba module. It enables the numba intrinsic compiler to optimize the decorated function and taylors it to the CPU architecture. \n",
    "\n",
    "In short, it takes the python generated bytecode of the decorated function and manages the type inferrence and compilation through LLVM (a compiler infrastructure project with lots of support for different CPU architectures and programming languages). \n",
    "\n",
    "It specifically compiles \"just in time\" for the CPU/GPU architecture you have. There is no need to make specific type definitions, and usually, it just works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some funky behavior\n",
    "def useless():\n",
    "    pass\n",
    "\n",
    "@jit\n",
    "def what():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time useless()\n",
    "%time what()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that jitting an empty function slows down the execution.\n",
    "This is because of the overhead caused by passing the bytecode generated by the python interpreter to the LLVM libraries where an empty function has to be translated. Executing the same function for a second time shows that the overhead vanishes since the function is now compiled.\n",
    "\n",
    "#### Now for some test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big data\n",
    "test_array = np.arange(1_000_000)\n",
    "test_list  = range(1_000_000)\n",
    "\n",
    "def function_py(inp_list):\n",
    "    \"\"\"\n",
    "    Pure python implementation.\n",
    "    NEVER DO THIS!\n",
    "    \"\"\"\n",
    "    out_list = []\n",
    "    for val in inp_list:\n",
    "        out_list.append(np.cos(val)**2 + np.sin(val)**2)\n",
    "    return out_list\n",
    "\n",
    "def function_np(inp):\n",
    "    \"\"\"\n",
    "    Making use of numpy ufuncs.\n",
    "    Numpy has the ability to broadcast single\n",
    "    operations on entire arrays by itself.\n",
    "    \"\"\"\n",
    "    return np.cos(inp)**2 + np.sin(inp)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = function_py(test_list)\n",
    "%time _ = function_np(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy's vectorized ufuncs are good, but it can be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def lazy_function(inp):\n",
    "    \"\"\"\n",
    "    The lazy compilation option.\n",
    "    Just write @jit before the function.\n",
    "    \"\"\"\n",
    "    return np.cos(inp)**2 + np.sin(inp)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = lazy_function(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in this case, that the first time compilation is slower than the pure numpy implementation.  \n",
    "This is again because of the compiler overhead.  \n",
    "Interestingly, if we increase the array size, the *jitted* function eventually becomes faster even at first call.  \n",
    "\n",
    "You can also explicitely tell numba, what it should expect as datatypes using a decorator signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nb.float64[:](nb.float64[:]))\n",
    "def eager_function(inp):\n",
    "    \"\"\"\n",
    "    Eager compilation option.\n",
    "    You can add a function signature to\n",
    "    the @jit decorator. The function will be\n",
    "    compiled expecting these datatypes as input\n",
    "    and output. Other datatypes will not be\n",
    "    accepted. This can be quite tricky...\n",
    "    \"\"\"\n",
    "    return np.cos(inp)**2 + np.sin(inp)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = eager_function(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using signatures, you have to make sure that you pass the correct datastructures into the function.  \n",
    "Otherwise it will give **errors** or show funky behavior.  \n",
    "The advantage is, that the time of first compilation is saved, since ***numba*** already knows what to expect.  \n",
    "A list of specifications for signatures can be found in the documentation:\n",
    "- `void` is the return type of functions returning nothing (which actually return None when called from Python)\n",
    "- `intp` and `uintp` are pointer-sized integers (signed and unsigned, respectively)\n",
    "- `intc` and `uintc` are equivalent to C int and unsigned int integer types\n",
    "- `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64` are fixed-width integers of the corresponding bit width (signed and unsigned)\n",
    "- `float32` and `float64` are single- and double-precision floating-point numbers, respectively\n",
    "- `complex64` and `complex128` are single- and double-precision complex numbers, respectively\n",
    "- array types can be specified by indexing any numeric type, e.g. `float32[:]` for a one-dimensional single-precision array or `int8[:,:]` for a two-dimensional array of 8-bit integers.\n",
    "\n",
    "Signature syntax follows: `out_type(in_type_1, in_type_2, ...)`  \n",
    "\n",
    "You can also set a list of signatures to 'overload' the function compilation.\n",
    "Always order from least specific to most specific:\n",
    "\n",
    "`int32 > int64 > float32 > float64`\n",
    "\n",
    "otherwise unexpected behaviour might occur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit([nb.float64[:](nb.int64[:]),\n",
    "      nb.float64[:](nb.float64[:])])\n",
    "def eager_function(inp):\n",
    "    \"\"\"\n",
    "    Multiple signatures for a single\n",
    "    function. Allows for various type\n",
    "    definitions. If  you intend to use\n",
    "    the jitted function with multiple\n",
    "    input types, its easier to let numba\n",
    "    figure it out, instead of wrting all\n",
    "    definitions yourself...\n",
    "    \"\"\"\n",
    "    return np.cos(inp)**2 + np.sin(inp)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some stupid example\n",
    "\n",
    "Here, we will look at an example where jitting doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function(inp_list):\n",
    "    \"\"\"\n",
    "    This example is directly taken from 'Jack of Some'\n",
    "    on YouTube. It is however a nice illustration, how\n",
    "    to NOT use numba\n",
    "    \"\"\"\n",
    "    out_list = []\n",
    "    for val in inp_list:\n",
    "        if val % 2 == 0:\n",
    "            out_list.append(2)\n",
    "        else:\n",
    "            out_list.append('1')\n",
    "    return out_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = some_function(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_some_function = jit()(some_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = jit_some_function(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *@jit* decorator can operate in two modes: *object mode* and *nopython mode*  \n",
    "In *object mode* numba will fallback to the standard python behavior of dynamic datatypes, in addition to the compilation overhead.  \n",
    "It is best to use the ***nopython*** option, as this will give **errors** instead of warnings, if *object mode* is invoked to resolve compilation.\n",
    "\n",
    "The shorthand for *nopython* jitting is `njit`  \n",
    "\n",
    "\n",
    "`jit(nopython=True) == njit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njit_some_function = njit()(some_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = njit_some_function(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function failed in nopython mode because a string can't be added to a integer list.\n",
    "This shows that numba requires type stability for datastructures like lists.  \n",
    "Python lists are generally problematic, since ***numba*** has to do extra work (list reflection)  \n",
    "to make sure the type of list entries is stable while going through the list.  \n",
    "Additional problems arise from not knowing how large the `out_list` will be, thus requiring extra time.\n",
    "\n",
    "Numba developers included new methods of dealing with lists by introducing 'typed.List' which can be imported from the numba module.  \n",
    "It is derived from python lists but has a fixed type:\n",
    "\n",
    "    import numba as nb\n",
    "    mylist = nb.typed.List()\n",
    "\n",
    "For the same reason, dictionaries and sets are only partially supported, but there should be typed versions of those as well, soon\n",
    "\n",
    "If you have the option, ALWAYS use `numpy` arrays\n",
    "\n",
    "### Let's fix the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function_fix(inp_arr):\n",
    "    \"\"\"\n",
    "    This example is directly taken from 'Jack of Some'\n",
    "    on YouTube. This is how the function should look like,\n",
    "    IF you intend to use @njit\n",
    "    \"\"\"\n",
    "    # replace empty list with pre-allocated array\n",
    "    # Careful with datatypes inside the function\n",
    "    # when using signatures !!!\n",
    "    out_arr = np.zeros_like(inp_arr)\n",
    "\n",
    "    # enumerate is supported by numba\n",
    "    for ii,val in enumerate(inp_arr):\n",
    "        if val % 2 == 0:\n",
    "            out_arr[ii] = 2\n",
    "        else:\n",
    "            out_arr[ii] = 1\n",
    "    return out_arr\n",
    "\n",
    "njit_some_function_fix = njit()(some_function_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = some_function_fix(test_array)\n",
    "%time _ = njit_some_function_fix(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the `enumerate` function, we explicitely require arrays as input to this function.  \n",
    "If we define an output array inside a *jitted* function and use signatures, we have to make sure that\n",
    "the datatype is the one we specified.  \n",
    "\n",
    "Not all python/numpy features are yet supported and there are way too many features to cover here.  \n",
    "Please refer to the official numba documentation for currently supported features.  \n",
    "For example, support for `np.logspace` was only added recently (as of **13th Jan. 2022**)\n",
    "\n",
    "Things like `try`-`except` or `raise`, `assert` are partially supported and limited in functionality as of yet.\n",
    "Check the documentation for specifics. Thus it might be advantageous to keep ***numba*** *up-to-date* if you,  \n",
    "even if some legacy features (reflected lists) might be deprecated in future releases.\n",
    "\n",
    "\n",
    "## The ***@vectorize*** decorator\n",
    "\n",
    "Similar to how numpy is able to apply scalar functions elementwise on entire arrays,  \n",
    "***numba*** comes with a similar option: Instead of explicitely passing arrays to function calls  \n",
    "and then explicitely loop over them, you can add the `@vectorize` decorator.  \n",
    "It will tell the compiler to implicitely allow for array inputs and apply the function elementwise.  \n",
    "Both methods (explicit and implicit) yield similar performance. Ultimately, it comes down to preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_function_np(inp):\n",
    "    \"\"\"\n",
    "    This example is directly taken from 'Jack of Some'\n",
    "    on YouTube. This is how the function should look like.\n",
    "    We will use numpy's own vectorize function\n",
    "    -----\n",
    "    Write 2 if inp is even, 1 if uneven\n",
    "    \"\"\"\n",
    "    if inp % 2 == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "@vectorize(nopython=True)\n",
    "def same_function(inp):\n",
    "    \"\"\"\n",
    "    This example is directly taken from 'Jack of Some'\n",
    "    on YouTube. This is how the function should look like,\n",
    "    IF you intend to use @vectorize\n",
    "    -----\n",
    "    Write 2 if inp is even, 1 if uneven\n",
    "    \"\"\"\n",
    "    if inp % 2 == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = same_function(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***numpy*** provides its own `vectorize` option which can create *ufuncs* for functions with branching  \n",
    "return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = np.vectorize(same_function_np)(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how much slower the ***numpy*** vectorization option is.  \n",
    "This is due to `np.vectorize` being a wrapper function for an explicit loop  \n",
    "over array elements. From the ***numpy*** documentation:\n",
    "> The `(np.)vectorize` function is provided primarily for convenience, not for performance. The implementation is essentially a for loop.  \n",
    "\n",
    "Since ***numba*** compiles its generated ufuncs, they achive similar speeds to ufuncs written in *C*\n",
    "\n",
    "There is also the ***@guvectorize*** decorator (generalized ufuncs), which is similar to ***@vectorize*** but is intended  \n",
    "for inplace manipulation of a result array given to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array = np.zeros_like(test_array)\n",
    "scalar = 1.\n",
    "\n",
    "@nb.guvectorize('(n),()->(n)')\n",
    "def g(x, y, res):\n",
    "    \"\"\"\n",
    "    Notice the special signature in the decorator.\n",
    "    (n)     : 1D-array input\n",
    "    ()      : scalar input\n",
    "    ->(n)   : 1D-array output\n",
    "    \"\"\"\n",
    "    for i in range(x.shape[0]):\n",
    "        res[i] = x[i] + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time g(test_array,scalar,out_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More sensible examples\n",
    "\n",
    "We will explore a classic benchmark test: calculating $\\pi$ using a Monte-Carlo simulation.  \n",
    "Additionally, I will show an example where I use ***numba*** it in my own research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example functions I use with numba\n",
    "\n",
    "Here are some examples where I use numba to gain some performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _sample(samp_arr: np.ndarray, CDF: np.ndarray, N: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    MC sampling of pseudo-CDF. Associates luminosities to population of XRBs \n",
    "    according to a given CDF. LumArr and CDF should have the same length\n",
    "    -----\n",
    "    samp_arr    :   Input array to sample value from (e.g. luminosity or energy)\n",
    "    CDF         :   Input CDF derived from model and samp_arr (e.g. XLFs or spectra). \n",
    "                    Should have the same length as LumArr\n",
    "    N           :   Population/Sample size. How often to sample from samp_arr.\n",
    "                    Needs to be integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    jj = 1\n",
    "    kk = 1\n",
    "    lum = np.zeros(N)\n",
    "    ranvec = np.sort( np.random.rand(N) )\n",
    "    \n",
    "    for ii in range(0,N):\n",
    "        jj = kk     # restart from jj where it arrived previously\n",
    "        if jj == len(CDF) - 1:\n",
    "            break   # otherwise, loop produces error due to overcounting\n",
    "        while ( CDF[jj] < ranvec[ii] ):\n",
    "            jj +=1\n",
    "            if jj == len(CDF) - 1:\n",
    "                break\n",
    "        kk == jj\n",
    "        lum[ii] = samp_arr[jj-1]+(samp_arr[jj]-samp_arr[jj-1])*(ranvec[ii]-CDF[jj-1])/(CDF[jj]-CDF[jj-1])\n",
    "    return lum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $\\pi$\n",
    "\n",
    "This is a classic test where you uniformly draw random points in a unit square with the origin at the left-bottom corner\n",
    "and then measure how many points have a radius of 1 from the origin. This yields the area of a quarte circle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nb.set_num_threads(4)\n",
    "\n",
    "@njit(nb.float64(nb.int64),parallel=True, nogil=True, fastmath=True)\n",
    "def monte_carlo_pi(nsamples):\n",
    "    \"\"\"\n",
    "    parallel:\n",
    "    enables the use of multiple threads\n",
    "    while running the function. By default it will\n",
    "    make use of pythons standard libraries like \n",
    "    multithreading/concurrent.futures to parallelize\n",
    "\n",
    "    nogil:\n",
    "    lifts the global interpreter lock. Useful\n",
    "    if you prefer a manual thread mapping\n",
    "\n",
    "    fastmath:\n",
    "    lifts floating point accuracy restriction (IEEE 719)\n",
    "    less strict accuracy requirements lead to speedup\n",
    "\n",
    "    prange:\n",
    "    numba substitue for the standard range() function.\n",
    "    It will fallback to range() if parallel=False.\n",
    "    Explicitely tells numba which loops to parallelize.\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    for i in nb.prange(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x ** 2 + y ** 2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time monte_carlo_pi(1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inevitable question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spng](./6gemz6.jpg)\n",
    "\n",
    "Ludwig kindly made a benchmark of this function with ***Julia***...\n",
    "\n",
    "His implementation takes **3.2 ms** on this same machine (cast1) on the second function call.\n",
    "\n",
    "The first function call, which is also used to compile the function in ***Julia*** (I think)  \n",
    "takes **36 ms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The @jitclass decorator\n",
    "\n",
    "A relatively new feature is the ***@jitclass*** decorator. By specifying the type of\n",
    "class attributes, ***numba*** enables jitting of the class.  \n",
    "All methods of the jitclass will be compiled in *nopython* mode.  \n",
    "Since it is still in development, not all features of ***@jit*** are implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.experimental import jitclass\n",
    "\n",
    "spec = [\n",
    "    (\"mass\",    nb.float32[:]),\n",
    "    (\"pos\",     nb.float32[:,:]),\n",
    "    (\"vel\",     nb.float32[:,:]),\n",
    "    (\"acc\",     nb.float32[:,:]),\n",
    "    (\"id\",      nb.uint32[:]),\n",
    "    (\"active\",  nb.boolean[:]),\n",
    "    (\"soft\",    nb.float32),\n",
    "    (\"N\",       nb.int64)\n",
    "]\n",
    "\n",
    "@jitclass(spec)\n",
    "class Nbody:\n",
    "    \"\"\"\n",
    "    spec:\n",
    "    Contains the class attributes and their datatypes\n",
    "    An __init__ method is required to initializw all \n",
    "    attributes given in the specification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N: int):\n",
    "        self.mass   = np.zeros(N, dtype=np.float32)\n",
    "        self.pos    = np.zeros((N,3), dtype=np.float32)\n",
    "        self.vel    = np.zeros((N,3), dtype=np.float32)\n",
    "        self.acc    = np.zeros((N,3), dtype=np.float32)\n",
    "        self.id     = np.arange(N, dtype=np.uint32)\n",
    "        self.active = np.zeros(N, dtype=nb.boolean)\n",
    "        self.soft   = .1\n",
    "        self.N      = N\n",
    "\n",
    "    def kick(self, dt):\n",
    "        self.vel += self.acc*dt\n",
    "\n",
    "    def drift(self,dt):\n",
    "        self.pos += self.vel*dt\n",
    "\n",
    "    def calc_acc(self):\n",
    "        \"\"\"\n",
    "        No parallel support yet. A possible solution\n",
    "        would be to have a jitted function external to\n",
    "        the class processing the arrays in parallel.\n",
    "        \"\"\"\n",
    "        for i in range(self.N):\n",
    "            self.acc[i] = np.zeros(3, dtype=np.float32)\n",
    "            for j in range(self.N):\n",
    "                if i != j:\n",
    "                    dist_vec = self.pos[i]-self.pos[j]\n",
    "                    dist = np.sqrt(dist_vec**2+self.soft)\n",
    "                    self.acc[i] += self.mass[j] / dist**3 * dist_vec\n",
    "\n",
    "    def _init_rand_pos(self, box=1.):\n",
    "        np.random.seed(123)\n",
    "        self.pos = np.random.uniform(0.,box,(self.N,3)).astype(np.float32)\n",
    "        self.mass = np.ones_like(self.mass)\n",
    "        self.acc = _calc_acc(self.mass, self.pos, self.soft, self.N)\n",
    "\n",
    "    def init_rand_pos(self, box=1.):\n",
    "        np.random.seed(123)\n",
    "        self.pos = np.random.uniform(0.,box,(self.N,3)).astype(np.float32)\n",
    "        self.mass = np.ones_like(self.mass)\n",
    "        self.calc_acc()\n",
    "\n",
    "nb.set_num_threads(4)\n",
    "\n",
    "@njit(nb.float32[:,:](nb.float32[:],nb.float32[:,:], nb.float32, nb.int64),parallel=True)\n",
    "def _calc_acc(mass_arr, pos_arr, soft, dim):\n",
    "    acc_arr = np.zeros((dim,3),dtype=np.float32)\n",
    "    for i in nb.prange(dim):\n",
    "        # acc_arr[i] = np.zeros(3, dtype=np.float32)\n",
    "        for j in range(dim):\n",
    "            if i != j:\n",
    "                dist_vec = pos_arr[i]-pos_arr[j]\n",
    "                dist = np.sqrt(dist_vec**2 + soft)\n",
    "                acc_arr[i] += mass_arr[j] / dist**3 * dist_vec\n",
    "    return acc_arr\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = Nbody(4_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.51 s, sys: 0 ns, total: 5.51 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%time part.init_rand_pos()\n",
    "a = part.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.2 s, sys: 15.9 ms, total: 9.21 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%time part._init_rand_pos()\n",
    "b = part.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "***numba*** is a very handy and powerful tool to significantly improve numeric python and  \n",
    "***numpy*** algorithms. It is especially useful, if your algorithms are already making heavy use  \n",
    "of numpy's features. By only adhereing to basic principles of type stability within loops  \n",
    "and a slightly unpythonic writing coding style, it can easily offer one to two orders of magnitude  \n",
    "performance boost. It supports many native python and numpy functions and Additionally,  \n",
    "it can benefit from other packages like ***scipy*** to improve functions used by `np.linalg`.  \n",
    "There is also the possibility to ***jit*** an entire module with the ***@jit_module*** decorator  \n",
    "and much more.\n",
    "\n",
    "![das](./6gf5ud.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX\n",
    "\n",
    "Stefan and Ilaria found an interesting edge case where numba really is more inefficient to use.\n",
    "\n",
    "Apparently, it cannot speedup some native functions of numpy as there isn't anything to improve.\n",
    "\n",
    "For example `np.sum` is already optimized to oblivion, numba only makes it perform worse by adding additional overhead.\n",
    "\n",
    "This is however only true if those calls are standalone. As soon as the algorithms become  slightly more complicated,\n",
    "\n",
    "numba can be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example was proposed by Stefan Heigl.\n",
    "# It shows that native numpy function can be\n",
    "# faster than their jitted counterparts.\n",
    "# This only applies to single calls of\n",
    "# numpy functions. Algoritms with more\n",
    "# computations or iterations still benefit,\n",
    "# even if native numpy functions are\n",
    "# involved...\n",
    "\n",
    "inp = np.ones((1024,1024,1024))\n",
    "\n",
    "def sum_np(arr):\n",
    "    return np.sum(arr)\n",
    "\n",
    "@njit\n",
    "def sum_nb(arr):\n",
    "    return np.sum(arr)\n",
    "\n",
    "@njit\n",
    "def sum_nb2(arr):\n",
    "    sum = 0.\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[0]):\n",
    "            for k in range(arr.shape[0]):\n",
    "                sum += arr[i,j,k]\n",
    "\n",
    "    return sum\n",
    "\n",
    "lol = inp.flatten()\n",
    "@njit\n",
    "def sum_nb3(arr):\n",
    "    sum = 0.\n",
    "    for i in range(lol.shape[0]):\n",
    "        sum += arr[i]\n",
    "\n",
    "    return sum"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb2bf00e020f2d2a6375fb9eb74fee57721869bf3df00ba48f7382a226250a90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('covfefe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
